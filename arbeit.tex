\documentclass[a4paper]{scrreprt}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage[german,linesnumbered,algoruled,longend,vlined]{algorithm2e}
\DontPrintSemicolon
\SetArgSty{}
\SetKw{KwOr}{or}
\SetKw{KwAnd}{and}
\SetKw{KwNot}{not}
\setlength{\algomargin}{3ex}

\usepackage[fixlanguage]{mybabelbib}
% \selectlanguage{ngerman}
\setbibliographyfont{title}{}
\setbibliographyfont{jtitle}{}
\setbibliographyfont{btitle}{\emph}
\setbibliographyfont{stitle}{\emph}
\setbibliographyfont{journal}{\emph}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{graphicx}
\usepackage[a4paper,bookmarks,bookmarksnumbered]{hyperref}
\usepackage[font=small,format=hang,labelfont=bf,figurename=Abb.,tablename=Tab.]{caption}
\usepackage{enumerate}

\newtheorem{satz}{Satz}[chapter]
\newtheorem{lemma}[satz]{Lemma}
\newtheorem{beobachtung}[satz]{Beobachtung}
\newtheorem{folgerung}[satz]{Folgerung}
\newtheorem{korollar}[satz]{Korollar}
\theoremstyle{definition}
\newtheorem{definition}[satz]{Definition}
\newenvironment{beweis}{\begin{proof}}{\end{proof}}

\graphicspath{{abbildungen/}}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%% Bitte nur ab hier Änderungen vornehmen %%%%%%%%%%%%%%%%%%%%%

\subject{Seminararbeit}
\title{Randomisierte Datenstrukturen - Treaps}
\author{Moritz Beck, Robert McDaniel}
\date{Eingereicht am 24. 06 2015} %TODO? Gehe davon aus, dass wir das am Mittwoch abgeben
\titlehead{Julius-Maximilians-Universität Würzburg\\
Institut für Informatik\\
Lehrstuhl für Informatik I\\
Effiziente Algorithmen und wissensbasierte Systeme}
\publishers{Betreuer:\\
Prof.\ Dr.\ Alexander Wolff\\
Dipl.-Inf.\ Philipp Kindermann}
\maketitle
\tableofcontents

%%%%% hier den Text einfügen

\chapter{Einführung}
\label{sec:intro}

Treaps sind eine baumartige Datenstruktur, bei der das Sortieren der eingefügten Daten auf zwei Arten erfolgt:
Zum Einen werden die Schlüssel wie in einem Binärbaum sortiert, und zum Anderen werden die Knoten durch eine Priorität wie in einem Heap sortiert.
In dieser Arbeit wird insbesondere auf eine Implementierung von Treaps eingegangen, bei der die Priorität zufällig gewählt wird.
Dies bringt einige Vorteile gegenüber anderen Baumarten, wie zum Beispiel eine hohe Wahrscheinlichkeit, einen balancierten Baum zu erhalten, was die Laufzeit von Operationen verbessert.

Im Laufe dieser Arbeit wird in Abschnitt \ref{sec:motivation} zuerst auf die Situation eingegangen, die zum Einsatz von Treaps führt.
Genauer wird in Abschnitt \ref{sec:motivationbasics} der Aufbau der Datenstruktur, die wir erreichen wollen, erklärt, in Abschnitt \ref{sec:binaryruntime} die Laufzeiten der gewünschten Methoden bei binären Suchbäumen aufgezeigt, und bei Abschnitt \ref{sec:binaryproblems} auf die Probleme bei Binärbäumen eingegangen.

In Abschnitt \ref{sec:treaps} werden Treaps als eine Lösung für diese Probleme dargestellt.
Genauer werden in Abschnitt \ref{sec:treapsbasics} die Grundlagen für den Aufbau von Treaps aufgezeigt, in Abschnitt \ref{sec:uniquetreaps} die Existenz eines eindeutigen Treaps für eine gegebene Menge an Paaren von Schlüsseln und Prioritäten bewiesen, was zeigt, dass die Insert-Reihenfolge bei Treaps egal ist. In Abschnitt \ref{sec:implementing} werden die gewünschten Methoden implementiert und in Pseudocode beschrieben.

%TODO Laufzeitanalyse

In Abschnitt \ref{sec:closing} wird ein Abschlussfazit gezogen, wobei noch einmal ein kurzer Vergleich zwischen Binärbäumen und Treaps gemacht wird. %TODO Und vielleicht noch mehr?

\chapter{Motivation}
\label{sec:motivation}

In diesem Kapitel wird der Grundbau der gewünschten Datenstruktur beschrieben und es werden Probleme aufgezeigt, die später mit Treaps gelöst werden.
Hauptsächlich geht es dabei um die Abhängigkeit der Laufzeiten bei Binärbäumen von der Höhe des Binärbaums und das Balancieren dieser Bäume.

\section{Grundmotivation}
\label{sec:motivationbasics}

Wir betrachten dieses grundsätzliche Problem:
Wir wollen eine Menge ${S_1, S_2, ...}$ von Elementen verwalten und dabei bestimmte Methoden für Anfragen und Änderungen unterstützen.
Jedes Element $i$ hat einen Schlüssel $k(i)$, wobei diese Schlüssel total geordnet sind und jeder einzigartig ist.
Die zu unterstützenden Methoden sind die folgenden:

\begin{itemize}
\item $S$ = MakeSet(): Erschafft eine neue, leere Menge $S$.
\item Insert($i, S$): Fügt das Item $i$ in die Menge $S$ ein.
\item Delete($k, S$): Löscht das Item mit dem Schlüssel $k$ aus der Menge $S$.
\item Find($k, S$): Gibt das Item mit dem Schlüssel $k$ aus der Menge $S$ zurück.
\item $S$ = Join($S_1, i, S_2$): Ersetze die Mengen $S_1, S_2$ mit der neuen Menge $S = S_1 \cup {i} \cup S_2$, wobei:
	\begin{itemize}
	\item für alle Items $j \in S_1$ gilt: $k(j) > k(i)$
	\item für alle Items $j \in S_2$ gilt: $k(j) < k(i)$
	\end{itemize} 
\item $S$ = Merge($S_1, S_2$): Ersetze die Mengen $S_1, S_2$ mit der neuen Menge $S = S_1 \cup S_2$, wobei für alle Items $i \in S_1$ und $j \in S_2$ gilt, dass $k(i) < k(j)$.
\item $S_1, S_2$ = Split($k, S$): Ersetze die Menge $S$ durch die Mengen $S_1, S_2$, wobei gilt:
	\begin{itemize}
	\item $S_1 = \{j \in S | k(j) < k\}$
	\item $S_2 = \{j \in S | k(j) > k\}$
	\end{itemize}
\end{itemize}

Es liegt nahe, zur Lösung dieses Problems die binären Suchbäume heranzuziehen, da diese die gestellten Voraussetzungen erfüllen.
Es stellt sich jedoch heraus, dass sich bei binären Suchbäumen neue Probleme auftreten, die im nächsten Kapitel genauer erläutert werden.

\section{Probleme bei binären Suchbäumen}
\label{sec:binaryproblems}

Um die Probleme zu sehen, die sich bei binären Suchbäumen anbahnen, müssen wir zuerst die Laufzeiten für die gewünschten Methoden anschauen. Bei dieser Tabelle drückt $h$ die Höhe des Baums aus, und $h_x$ drückt die Höhe von Baum $S_x$ aus.

\begin{tabular}{l|c}
	Methode & Laufzeit\\
	\hline
	$S$ = MakeSet() & $O(1)$\\
	Insert$(i, S)$ & $O(h)$ \\
	Delete$(k, S)$ & $O(h)$ \\
	Find$(k, S)$ & $O(h)$ \\
	$S$ = Join($S_1, i, S_2$) & $O(1)$ \\
	$S$ = Merge($S_1, S_2$) & $O(h_1 + h_2)$ \\
	$S_1, S_2$ = Split$(k, S)$ & $O(h)$
\end{tabular}

%TODO Tabelle schöner machen, Label einfügen, Tabelle richtig platzieren und so weiter - ich kenn mich mit dem Zeug nicht so aus
%   --> \begin{figure}label{tab:binarytree}\caption[Laufzeiten Binärbaum]{Laufzeiten Binärbaum (ausführlichere Beschreibung hier als Bildunterschrift möglich)} ... \end{figure}

Man sieht recht einfach, dass beim binären Suchbaum die Laufzeit vieler Methoden direkt von der Höhe des Baums abhängen. 
Dies heißt, dass die amortisierte Laufzeit zwischen best-case und worst-case zwischen $O(log(n))$ und $O(n)$ schwankt.
Da ein Zustand nahe dem worst-case leicht auftreten kann, liegt es nahe, den Suchbaum auf irgendeine Weise zu optimieren, ob es über die Reihenfolge der Insert-Operationen oder über reguläres Rotieren und Reorganisieren der Knoten erreicht wird. \par

Eine vorherige Optimierung des Baums sieht nach einer guten Lösung für das Problem aus, es bringt jedoch andere, neue Probleme mit sich mit:
Wenn die Datenstruktur die Optimierung übernehmen soll, führt das zu einer erhöhten Komplexität der Implementierung. 
Die Methoden werden komplizierter, und es erhöht sich die Chance, dass sich Fehler darin einschleichen. 
Weiterhin bringt eine kompliziertere Implementierung eine höhere Laufzeit, auch wenn es sich nicht direkt in der amortisierten Version niederschlägt - es müssen offensichtlich mehr Operationen ausgeführt werden, um den Baum balanciert zu halten. 
Außerdem kann es notwendig sein, dass in der Implementierung zusätzliche Information gespeichert werden muss, die zum Balancieren benötigt wird. 
Wenn ein geringer Verbrauch an Speicherplatz wichtig ist, kann dies ebenfalls ein großes Problem darstellen. \par

Die Lösung für diese Probleme, die in dieser Arbeit näher dargestellt wird, ist Randomisierung.
Sie ist einfach zu implementieren, schnell auszuführen und benötigt keine weitere Speicherung von Balancing-Informationen, wenn sie zum Beispiel durch Hash-Funktionen erreicht wird.
Im nächsten Kapitel wird darauf eingegangen, wie eine Datenstruktur durch Einsatz von Randomisierung es sehr wahrscheinlich macht, dass der erstellte Baum zum best-case hin tendiert. 

%TODO Passt das so? Vielleicht noch mehr? Keine Ahnung, wie viel der Rest noch wird

\chapter{Treaps}
\label{sec:treaps}

\section{Grundlagen}
\label{sec:treapsbasics}

\section{Existenz eindeutiger Treaps}
\label{sec:uniquetreaps}

\section{Implementierung}
\label{sec:implementing}
% TODO: erkläre Rotation: - erhält Suchbaumeigenschaft, verändert die Reihenfolge zweier Knoten bzgl. Priorität
%       erkläre nach unten/oben rotieren (normalerweise ist die Definition Rechts-/Linksrotation)

\subsection{Find}
\label{sec:find}

\subsection{Insert}
\label{sec:insert}

\subsection{Delete}
\label{sec:delete}

\subsection{Join}
\label{sec:join}

\subsection{Merge}
\label{sec:merge}

\subsection{Split}
\label{sec:split}

\section{Laufzeitanalyse}
\label{sec:runtime}
Zur Laufzeitanalyse führen wir so genannte \emph{Mulmuley-Spiele} ein.
Diese werden wir analysieren und dadurch die Tiefe von Knoten in einem Treap und die Anzahl der benötigten Rotationen beim Löschen berechnen.
Das genügt, um die Laufzeit aller Operationen zu erhalten.

\subsection{Mulmuley-Spiele}
\label{sec:mulmuley}
Für ein Mulmuley-Spiel werden folgende disjunkte Mengen definiert: % TODO: fordere, dass die Mengen nicht leer sind?
\begin{itemize}
    \item Eine Menge $P = \{P_1, P_2, \dots, P_p\}$ von $p$ \emph{Spielern},
    \item eine Menge $S = \{S_1, S_2, \dots, S_s\}$ von $s$ \emph{Stoppern},
    \item eine Menge $T = \{T_1, T_2, \dots, T_t\}$ von $t$ \emph{Triggern},
    \item eine Menge $B = \{B_1, B_2, \dots, B_b\}$ von $b$ \emph{Zuschauern}.
\end{itemize}
Die Elemente aus $P \cup S$ seien aus einem total geordnetem Universum, und dabei sollen die Spieler kleiner sein als die Stopper.
Die Mengen $T$ und $B$ können beliebig sein.
Bilde eine Menge $X$, indem man mehrere dieser vier Mengen vereinigt und ziehe aus dieser zufällig Elemente ohne Zurücklegen.
Man zählt dabei die Anzahl der Spieler, die größer sind als alle bisher gezogenen Spieler, wobei Stopper ebenfalls als Spieler gezählt werden.
Der Wert eines Spieles entspricht dem erwarteten Wert für diese Anzahl und ist damit abhängig von der Kardinalität der einzelnen Mengen.
In dieser Arbeit werden 3 Varianten der Mulmuley-Spiele vorgestellt:
In Spiel A besteht die Menge $X$ aus den Spielern $P$ und den Zuschauern $B$.
Gezogen wird solange die Menge $X$ nicht leer ist.
In Spiel C besteht die Menge $X$ aus den Spielern $P$, den Stoppern $S$ und den Zuschauern $B$,
Gezogen wird solange bis der erste Stopper gezogen wurde.
In Spiel D besteht die Menge $X$ aus den Spielern $P$, den Triggern $T$ und den Zuschauern $B$.
Gezogen wird solange die Menge $X$ nicht leer ist, allerdings fängt man erst mit dem Zählen an, wenn der erste Trigger gezogen wurde.

Der Wert $A^p$ von Spiel A mit $p$ Spielern beträgt $H_p$. % TODO: \cite{...}
Dabei ist $H_p := \sum_{i=1}^p 1/p$ die p-te harmonische Zahl und es gilt $H_p \in \Theta(\log p)$. % TODO? \cite{...}
Der Wert $C_s^p$ von Spiel B mit $p$ Spielern und $s$ Stoppern beträgt $1 + H_{s+p} - H_s$.
Der  Wert $D_t^p$ von Spiel C mit $p$ Spielern und $t$ Triggern beträgt $H_p + H_t - H_{t+p}$.

\subsection{Laufzeit von Delete}
\label{sec:delruntime}
In diesem Unterabschnitt wird die Laufzeit einer Delete-Operation analysiert.
Dies ist ausreichend, da Insert genau den umgekehrten Ablauf hat wie Delete (\glqq Delete rückwärts\grqq), deshalb die gleiche Laufzeit hat, und die restlichen Operationen mit Hilfe einer konstanten Anzahl von Insert und Delete implementiert werden können. % TODO: beweisen? verlinken?

Die Ausführung von Delete besteht aus 2 Phasen:
Zuerst wird der zu löschende Knoten im Treap gesucht, um dann in der zweiten Phase bis nach unten rotiert zu werden.
Die Laufzeit der ersten Phase hängt linear von der Tiefe des gesuchten Knotens im Baum ab.
Der Knoten wird in der zweiten Phase entlang des linken \emph{Grats} des rechten Teilbaums und des rechten Grats des linken Teilbaums nach unten rotiert.
Der linke/rechte Grat eines Baums ist definiert als der Weg, den man erhält, wenn man von der Wurzel aus immer zum linken/rechten Kindknoten absteigt.
Also ist die Laufzeit der zweiten Phase proportional zur Summe dieser beiden Grate.

Sei $X$ mit $\left|X\right| = n$ die Menge aller Knoten in einem Treap.
Sei $x$ ein Knoten mit Rang $r$, d.h. es gibt $r$ Knoten, deren Schlüssel nicht größer sind, als der von $x$.
Sei $X_\leq$ die Menge aller $r$ Knoten mit Schlüssel kleiner oder gleich $k(x)$.
Analog definiere $X_\geq$.
Zur Analyse beginnen wir mit einem leeren Treap und fügen seine Knoten nach absteigender Priorität ein.
Dies ergibt, wie oben gezeigt, genau den zu analysierenden Treap, wobei Knoten immer nur als Blatt eingefügt werden und keine Rotationen erforderlich sind.
Wie in Randomized Algorithms\cite{TODO} gezeigt, sind die Knoten aus $X_\leq$, die sich entlang des Suchpfades von $x$ befinden, genau die Knoten, die zu dem Zeitpunkt, in dem sie eingefügt werden, die größten aus $X_\leq$ sind.
Möchte man die Anzahl dieser Knoten zählen, spielt man im Prinzip Spiel A mit $P = X_\leq$ und $B = X \setminus X_\leq$.
Damit ergibt sich ein erwartete Anzahl von $H_{\left|P\right|} = H_r$.
Betrachtet man auch die Knoten entlang des Suchpfades aus $X_\geq$, so ergibt sich aus Symmetriegründen eine erwartete Tiefe von $H_r + H_{n-r+1} - 1 \in O(\log n)$ für den Knoten $x$.
% TODO: Bild einfügen
Ähnlich kann man auch für die Anzahl der Rotationen argumentieren.
Hierbei spielt man Spiel D mit $P = X_\leq \setminus \{x\}$, $T = \{x\}$ und $B = X \setminus X_\leq$, das den Erwartungswert $H_{r-1} + H_1 - H_r = 1 - 1/r$ hat.
Für die Gesamtzahl der Rotationen ergibt sich damit erwartet $2 - 1/r - 1/(n-r+1) < 2$.

\chapter{Fazit}
\label{sec:closing}
% Vorteil ggü naiver BT: Balancing -> Laufzeit, gerade, wenn Elemente in auf-/absteigender Reihenfolge eingefügt werden
% Vorteil ggü det. balancierter BT: einfache Implementierung, keine weiteren Informationen/Speicher nötig -> Hashfunktion
% Tabelle mit Laufzeitvergleich


\bibliographystyle{mybabalpha-fl}
\bibliography{mybib}

\end{document}
